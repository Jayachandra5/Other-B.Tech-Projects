{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVsi3VWvhoeW",
        "outputId": "a701033d-be89-4061-9992-bd02ca506bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Binary BoWs: 0.9807070101857399\n",
            "Accuracy with tf-idf BoWs: 0.982444577591372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with tf-idf weighted average of word vectors: 0.984062312762133\n",
            "Accuracy with Doc2Vec: 0.917974835230677\n"
          ]
        }
      ],
      "source": [
        "# Model For finding wheather the mail is spam or not\n",
        "# Name :- Kothamasu Jayachandra\n",
        "# Roll Number :- 2110110293\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec, Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Nlp/combined_data.csv\")\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "X = data[\"text\"]\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# a) Binary BoWs\n",
        "binary_vectorizer = CountVectorizer(binary=True)\n",
        "X_train_binary = binary_vectorizer.fit_transform(X_train)\n",
        "X_test_binary = binary_vectorizer.transform(X_test)\n",
        "\n",
        "# Train Random Forest on Binary BoWs\n",
        "rf_binary = RandomForestClassifier()\n",
        "rf_binary.fit(X_train_binary, y_train)\n",
        "y_pred_binary = rf_binary.predict(X_test_binary)\n",
        "binary_accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Accuracy with Binary BoWs:\", binary_accuracy)\n",
        "\n",
        "# b) tf-idf BoWs\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train Random Forest on tf-idf BoWs\n",
        "rf_tfidf = RandomForestClassifier()\n",
        "rf_tfidf.fit(X_train_tfidf, y_train)\n",
        "y_pred_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
        "tfidf_accuracy = accuracy_score(y_test, y_pred_tfidf)\n",
        "print(\"Accuracy with tf-idf BoWs:\", tfidf_accuracy)\n",
        "\n",
        "# c) Word vectors - Word2Vec\n",
        "word_tokenized_text = [word_tokenize(text.lower()) for text in data['text']]\n",
        "word2vec_model = Word2Vec(sentences=word_tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_model.train(word_tokenized_text, total_examples=len(word_tokenized_text), epochs=10)\n",
        "\n",
        "# d) Word vectors - tf-idf weighted average\n",
        "# Fit tf-idf vectorizer on the training data\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a dictionary to map each word to its tf-idf weight\n",
        "word_to_tfidf = dict(zip(feature_names, tfidf_vectorizer.idf_))\n",
        "\n",
        "# Function to calculate tf-idf weighted average of word vectors for a document\n",
        "def calculate_weighted_average(words, word_vectors, word_to_tfidf):\n",
        "    word_vector_dim = word_vectors.vector_size  # Use vector_size attribute instead of shape\n",
        "    weighted_average = np.zeros(word_vector_dim)\n",
        "    total_weight = 0\n",
        "    for word in words:\n",
        "        if word in word_to_tfidf and word in word_vectors:\n",
        "            weighted_average += word_vectors[word] * word_to_tfidf[word]\n",
        "            total_weight += word_to_tfidf[word]\n",
        "    if total_weight != 0:\n",
        "        weighted_average /= total_weight\n",
        "    return weighted_average\n",
        "\n",
        "\n",
        "# Calculate tf-idf weighted average for each document in the training set\n",
        "X_train_weighted_average = []\n",
        "for text in X_train:\n",
        "    words = word_tokenize(text.lower())\n",
        "    weighted_average = calculate_weighted_average(words, word2vec_model.wv, word_to_tfidf)\n",
        "    X_train_weighted_average.append(weighted_average)\n",
        "\n",
        "# Convert to numpy array\n",
        "X_train_weighted_average = np.array(X_train_weighted_average)\n",
        "\n",
        "# Train Random Forest on tf-idf weighted average of word vectors\n",
        "rf_weighted_average = RandomForestClassifier()\n",
        "rf_weighted_average.fit(X_train_weighted_average, y_train)\n",
        "\n",
        "# Calculate tf-idf weighted average for each document in the test set and predict\n",
        "X_test_weighted_average = []\n",
        "for text in X_test:\n",
        "    words = word_tokenize(text.lower())\n",
        "    weighted_average = calculate_weighted_average(words, word2vec_model.wv, word_to_tfidf)\n",
        "    X_test_weighted_average.append(weighted_average)\n",
        "\n",
        "# Convert to numpy array\n",
        "X_test_weighted_average = np.array(X_test_weighted_average)\n",
        "\n",
        "# Predict\n",
        "y_pred_weighted_average = rf_weighted_average.predict(X_test_weighted_average)\n",
        "weighted_average_accuracy = accuracy_score(y_test, y_pred_weighted_average)\n",
        "print(\"Accuracy with tf-idf weighted average of word vectors:\", weighted_average_accuracy)\n",
        "\n",
        "# e) Document vectors using Doc2Vec\n",
        "documents = [TaggedDocument(words=word_tokenize(text.lower()), tags=[str(i)]) for i, text in enumerate(data['text'])]\n",
        "doc2vec_model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
        "\n",
        "# Train Random Forest on Doc2Vec representations\n",
        "doc_vectors = [doc2vec_model.infer_vector(word_tokenize(text.lower())) for text in X_train]\n",
        "X_train_doc2vec = pd.DataFrame(doc_vectors)\n",
        "rf_doc2vec = RandomForestClassifier()\n",
        "rf_doc2vec.fit(X_train_doc2vec, y_train)\n",
        "\n",
        "# Infer vectors for test data and predict\n",
        "doc_vectors_test = [doc2vec_model.infer_vector(word_tokenize(text.lower())) for text in X_test]\n",
        "X_test_doc2vec = pd.DataFrame(doc_vectors_test)\n",
        "y_pred_doc2vec = rf_doc2vec.predict(X_test_doc2vec)\n",
        "doc2vec_accuracy = accuracy_score(y_test, y_pred_doc2vec)\n",
        "print(\"Accuracy with Doc2Vec:\", doc2vec_accuracy)\n"
      ]
    }
  ]
}